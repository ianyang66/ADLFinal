{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_chapter_items_df = pd.read_csv('./data/course_chapter_items.csv')\n",
    "#chapter_items_seq = pd.read_csv('./data/course_chapter_items_sequence.csv')\n",
    "course_df = pd.read_csv('./data/courses.csv')\n",
    "users_df = pd.read_csv('./data/users.csv')\n",
    "subgroups_df = pd.read_csv('./data/subgroups.csv')\n",
    "\n",
    "train_group_df = pd.read_csv('./data/train_group.csv')\n",
    "test_seen_group_df = pd.read_csv('./data/test_seen_group.csv')\n",
    "val_seen_group_df = pd.read_csv('./data/val_seen_group.csv')\n",
    "test_unseen_group_df = pd.read_csv('./data/test_unseen_group.csv')\n",
    "val_unseen_group_df = pd.read_csv('./data/val_unseen_group.csv')\n",
    "\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_seen_df = pd.read_csv('./data/test_seen.csv')\n",
    "val_seen_df = pd.read_csv('./data/val_seen.csv')\n",
    "test_unseen_df = pd.read_csv('./data/test_unseen.csv')\n",
    "val_unseen_df = pd.read_csv('./data/val_unseen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>course_name</th>\n",
       "      <th>course_price</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_intro</th>\n",
       "      <th>groups</th>\n",
       "      <th>sub_groups</th>\n",
       "      <th>groups+subgroups</th>\n",
       "      <th>topics</th>\n",
       "      <th>course_published_at_local</th>\n",
       "      <th>description</th>\n",
       "      <th>will_learn</th>\n",
       "      <th>required_tools</th>\n",
       "      <th>recommended_background</th>\n",
       "      <th>target_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61888e868f154b000781b45a</td>\n",
       "      <td>少女人妻華麗變身：七大妝容七彩的夢幻樂園</td>\n",
       "      <td>1800</td>\n",
       "      <td>61888e7bb7fe1c0006850eff</td>\n",
       "      <td>在美妝 KOL 圈裡屬個人風格強烈的 Alice，在清新與叛逆風格間遊刃有餘，其幽默的美妝影...</td>\n",
       "      <td>生活品味</td>\n",
       "      <td>更多生活品味,護膚保養與化妝</td>\n",
       "      <td>生活品味_更多生活品味,生活品味_護膚保養與化妝</td>\n",
       "      <td>更多生活品味,護膚保養與化妝</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;img src=\"https://images.api.hahow.in/images/6...</td>\n",
       "      <td>不再害怕各種顏色的彩妝，可以更隨心搭配各種繽紛的顏色。\\n</td>\n",
       "      <td>所需工具為：視課程實際會用到的彩妝用品</td>\n",
       "      <td>只要你有一顆愛化妝、想變漂亮的心皆可以參加。\\n\\n⚠️ 雖然課程當中會帶到相關彩妝技巧，不...</td>\n",
       "      <td>熱愛彩妝的人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54d5a117065a7e0e00725ac0</td>\n",
       "      <td>幾何圖形分割 X 色塊組合</td>\n",
       "      <td>100</td>\n",
       "      <td>54d5a079065a7e0e00725abe</td>\n",
       "      <td>從學生時代開始摸索photoshop等軟體，自以為有些天賦但後來發現其實沒有。出社會後從事美...</td>\n",
       "      <td>藝術,設計</td>\n",
       "      <td>平面設計,繪畫與插畫</td>\n",
       "      <td>設計_平面設計,藝術_繪畫與插畫</td>\n",
       "      <td>Illustrator/以拉,配色技巧</td>\n",
       "      <td>42090.98472</td>\n",
       "      <td>&lt;img src=\"https://storage.googleapis.com/hahow...</td>\n",
       "      <td>可以將任何區塊分割成自己想要的幾何圖形、快速的上色，並且能夠應用在許多地方</td>\n",
       "      <td>Adobe Illustrator（必備）, camera</td>\n",
       "      <td>知道如何使用Illustrator的基本工具列</td>\n",
       "      <td>每一位興趣的人都能學得來，非常容易的小技巧</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  course_id           course_name  course_price  \\\n",
       "0  61888e868f154b000781b45a  少女人妻華麗變身：七大妝容七彩的夢幻樂園          1800   \n",
       "1  54d5a117065a7e0e00725ac0         幾何圖形分割 X 色塊組合           100   \n",
       "\n",
       "                 teacher_id  \\\n",
       "0  61888e7bb7fe1c0006850eff   \n",
       "1  54d5a079065a7e0e00725abe   \n",
       "\n",
       "                                       teacher_intro groups      sub_groups  \\\n",
       "0  在美妝 KOL 圈裡屬個人風格強烈的 Alice，在清新與叛逆風格間遊刃有餘，其幽默的美妝影...   生活品味  更多生活品味,護膚保養與化妝   \n",
       "1  從學生時代開始摸索photoshop等軟體，自以為有些天賦但後來發現其實沒有。出社會後從事美...  藝術,設計      平面設計,繪畫與插畫   \n",
       "\n",
       "           groups+subgroups               topics  course_published_at_local  \\\n",
       "0  生活品味_更多生活品味,生活品味_護膚保養與化妝       更多生活品味,護膚保養與化妝                        NaN   \n",
       "1          設計_平面設計,藝術_繪畫與插畫  Illustrator/以拉,配色技巧                42090.98472   \n",
       "\n",
       "                                         description  \\\n",
       "0  <img src=\"https://images.api.hahow.in/images/6...   \n",
       "1  <img src=\"https://storage.googleapis.com/hahow...   \n",
       "\n",
       "                              will_learn                 required_tools  \\\n",
       "0          不再害怕各種顏色的彩妝，可以更隨心搭配各種繽紛的顏色。\\n            所需工具為：視課程實際會用到的彩妝用品   \n",
       "1  可以將任何區塊分割成自己想要的幾何圖形、快速的上色，並且能夠應用在許多地方  Adobe Illustrator（必備）, camera   \n",
       "\n",
       "                              recommended_background           target_group  \n",
       "0  只要你有一顆愛化妝、想變漂亮的心皆可以參加。\\n\\n⚠️ 雖然課程當中會帶到相關彩妝技巧，不...                 熱愛彩妝的人  \n",
       "1                            知道如何使用Illustrator的基本工具列  每一位興趣的人都能學得來，非常容易的小技巧  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課程 Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "130566"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2course_mapping = course_df[\"course_id\"].to_dict()\n",
    "course2id_mapping = {v : k for k, v in id2course_mapping.items()}\n",
    "len(course2id_mapping)\n",
    "\n",
    "id2course_mapping = course_df[\"course_id\"].to_dict()\n",
    "course2id_mapping = {v : k for k, v in id2course_mapping.items()}\n",
    "print(len(course2id_mapping))\n",
    "\n",
    "id2user_mapping = users_df[\"user_id\"].to_dict()\n",
    "user2id_mapping = {v : k for k, v in id2user_mapping.items()}\n",
    "len(id2user_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_name</th>\n",
       "      <th>teacher_intro</th>\n",
       "      <th>groups</th>\n",
       "      <th>sub_groups</th>\n",
       "      <th>topics</th>\n",
       "      <th>will_learn</th>\n",
       "      <th>recommended_background</th>\n",
       "      <th>target_group</th>\n",
       "      <th>required_tools</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>少女人妻華麗變身：七大妝容七彩的夢幻樂園</td>\n",
       "      <td>在美妝KOL圈裡屬個人風格強烈的Alice，在清新與叛逆風格間遊刃有餘，其幽默的美妝影片手法...</td>\n",
       "      <td>生活品味</td>\n",
       "      <td>更多生活品味,護膚保養與化妝</td>\n",
       "      <td>更多生活品味,護膚保養與化妝</td>\n",
       "      <td>不再害怕各種顏色的彩妝，可以更隨心搭配各種繽紛的顏色。\\n</td>\n",
       "      <td>只要你有一顆愛化妝、想變漂亮的心皆可以參加。\\n\\n⚠️雖然課程當中會帶到相關彩妝技巧，不過...</td>\n",
       "      <td>熱愛彩妝的人</td>\n",
       "      <td>所需工具為：視課程實際會用到的彩妝用品</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>幾何圖形分割X色塊組合</td>\n",
       "      <td>從學生時代開始摸索photoshop等軟體，自以為有些天賦但後來發現其實沒有。出社會後從事美...</td>\n",
       "      <td>藝術,設計</td>\n",
       "      <td>平面設計,繪畫與插畫</td>\n",
       "      <td>Illustrator/以拉,配色技巧</td>\n",
       "      <td>可以將任何區塊分割成自己想要的幾何圖形、快速的上色，並且能夠應用在許多地方</td>\n",
       "      <td>知道如何使用Illustrator的基本工具列</td>\n",
       "      <td>每一位興趣的人都能學得來，非常容易的小技巧</td>\n",
       "      <td>AdobeIllustrator（必備）,camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>數位拼貼的手感</td>\n",
       "      <td>自由工作者，致力於品牌視覺規劃，包含識別系統設計、平面設計、包裝設計、網頁、插畫製作等，偶爾...</td>\n",
       "      <td>藝術,設計</td>\n",
       "      <td>平面設計,電腦繪圖</td>\n",
       "      <td>photoshop</td>\n",
       "      <td>藉由這堂課，可以學習到如何利用身邊的物件自製素材，了解去背、Photoshop的基本操作，並...</td>\n",
       "      <td></td>\n",
       "      <td>繪圖軟體初學者；喜歡隨性創作；常天馬行空；喜歡剪剪貼貼或收集東西，卻不知該如何收藏。</td>\n",
       "      <td>軟體：AdobePhotoshop、AdobeIllustrator；\\n設備：電腦、相機、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Line的貼圖自己動手做！</td>\n",
       "      <td>我是Danny，現是一名自由接案的插畫師，主要是做插畫設計、人物設計、AppUI設計，201...</td>\n",
       "      <td>藝術,設計</td>\n",
       "      <td>平面設計,應用設計,電腦繪圖</td>\n",
       "      <td>LINE貼圖設計,photoshop</td>\n",
       "      <td>如果上完課之後好好練習(不懂的地方隨時提問)，就可以畫出你在一般市面上看的到的line貼圖(...</td>\n",
       "      <td>只要手可以拿得起鉛筆和握滑鼠就可以</td>\n",
       "      <td>喜歡畫畫，但是沒有學過電腦繪圖的人、想學基本的電腦繪圖但不知如何入手的人，從10歲-100歲...</td>\n",
       "      <td>Photoshop(可至官網下載試用版)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>為申請學校或工作寫好英文自傳</td>\n",
       "      <td>在北美長大，回到南台灣尋根後，現落腳於南加州的庄腳嬰仔。在鑽研細胞奈米科學與皮膚再生醫學的過...</td>\n",
       "      <td>職場技能,語言</td>\n",
       "      <td>求職,英文</td>\n",
       "      <td>商用英文,履歷撰寫</td>\n",
       "      <td>Apersonalstatementthatyoucanbeproudof,andarewa...</td>\n",
       "      <td>HowtouseGoogleDoc.BasicEnglishlisteningcompreh...</td>\n",
       "      <td>Peopleapplyingforcollege/post-graduatestudieso...</td>\n",
       "      <td>GoogleDocwillbeusedtosubmit/shareyourassignmen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            course_name                                      teacher_intro  \\\n",
       "0  少女人妻華麗變身：七大妝容七彩的夢幻樂園  在美妝KOL圈裡屬個人風格強烈的Alice，在清新與叛逆風格間遊刃有餘，其幽默的美妝影片手法...   \n",
       "1           幾何圖形分割X色塊組合  從學生時代開始摸索photoshop等軟體，自以為有些天賦但後來發現其實沒有。出社會後從事美...   \n",
       "2               數位拼貼的手感  自由工作者，致力於品牌視覺規劃，包含識別系統設計、平面設計、包裝設計、網頁、插畫製作等，偶爾...   \n",
       "3         Line的貼圖自己動手做！  我是Danny，現是一名自由接案的插畫師，主要是做插畫設計、人物設計、AppUI設計，201...   \n",
       "4        為申請學校或工作寫好英文自傳  在北美長大，回到南台灣尋根後，現落腳於南加州的庄腳嬰仔。在鑽研細胞奈米科學與皮膚再生醫學的過...   \n",
       "\n",
       "    groups      sub_groups               topics  \\\n",
       "0     生活品味  更多生活品味,護膚保養與化妝       更多生活品味,護膚保養與化妝   \n",
       "1    藝術,設計      平面設計,繪畫與插畫  Illustrator/以拉,配色技巧   \n",
       "2    藝術,設計       平面設計,電腦繪圖            photoshop   \n",
       "3    藝術,設計  平面設計,應用設計,電腦繪圖   LINE貼圖設計,photoshop   \n",
       "4  職場技能,語言           求職,英文            商用英文,履歷撰寫   \n",
       "\n",
       "                                          will_learn  \\\n",
       "0                      不再害怕各種顏色的彩妝，可以更隨心搭配各種繽紛的顏色。\\n   \n",
       "1              可以將任何區塊分割成自己想要的幾何圖形、快速的上色，並且能夠應用在許多地方   \n",
       "2  藉由這堂課，可以學習到如何利用身邊的物件自製素材，了解去背、Photoshop的基本操作，並...   \n",
       "3  如果上完課之後好好練習(不懂的地方隨時提問)，就可以畫出你在一般市面上看的到的line貼圖(...   \n",
       "4  Apersonalstatementthatyoucanbeproudof,andarewa...   \n",
       "\n",
       "                              recommended_background  \\\n",
       "0  只要你有一顆愛化妝、想變漂亮的心皆可以參加。\\n\\n⚠️雖然課程當中會帶到相關彩妝技巧，不過...   \n",
       "1                            知道如何使用Illustrator的基本工具列   \n",
       "2                                                      \n",
       "3                                  只要手可以拿得起鉛筆和握滑鼠就可以   \n",
       "4  HowtouseGoogleDoc.BasicEnglishlisteningcompreh...   \n",
       "\n",
       "                                        target_group  \\\n",
       "0                                             熱愛彩妝的人   \n",
       "1                              每一位興趣的人都能學得來，非常容易的小技巧   \n",
       "2         繪圖軟體初學者；喜歡隨性創作；常天馬行空；喜歡剪剪貼貼或收集東西，卻不知該如何收藏。   \n",
       "3  喜歡畫畫，但是沒有學過電腦繪圖的人、想學基本的電腦繪圖但不知如何入手的人，從10歲-100歲...   \n",
       "4  Peopleapplyingforcollege/post-graduatestudieso...   \n",
       "\n",
       "                                      required_tools  \n",
       "0                                所需工具為：視課程實際會用到的彩妝用品  \n",
       "1                        AdobeIllustrator（必備）,camera  \n",
       "2  軟體：AdobePhotoshop、AdobeIllustrator；\\n設備：電腦、相機、...  \n",
       "3                               Photoshop(可至官網下載試用版)  \n",
       "4  GoogleDocwillbeusedtosubmit/shareyourassignmen...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(x):\n",
    "    return x.replace(\" \", \"\")\n",
    "\n",
    "fillna=course_df.fillna('')\n",
    "features= ['course_name', 'teacher_intro', 'groups', 'sub_groups', 'topics', 'will_learn', 'recommended_background', 'target_group', 'required_tools']\n",
    "fillna=fillna[features]\n",
    "for feature in features:\n",
    "    fillna[feature] = fillna[feature].apply(clean_data)\n",
    "    \n",
    "fillna.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    少女人妻華麗變身：七大妝容七彩的夢幻樂園 在美妝KOL圈裡屬個人風格強烈的Alice，在清新...\n",
       "1    幾何圖形分割X色塊組合 從學生時代開始摸索photoshop等軟體，自以為有些天賦但後來發現...\n",
       "2    數位拼貼的手感 自由工作者，致力於品牌視覺規劃，包含識別系統設計、平面設計、包裝設計、網頁、...\n",
       "3    Line的貼圖自己動手做！ 我是Danny，現是一名自由接案的插畫師，主要是做插畫設計、人物...\n",
       "4    為申請學校或工作寫好英文自傳 在北美長大，回到南台灣尋根後，現落腳於南加州的庄腳嬰仔。在鑽研...\n",
       "Name: combination, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_combination(x):\n",
    "    course_name = x['course_name']\n",
    "    teacher_intro = x['teacher_intro']\n",
    "    will_learn = x['will_learn']\n",
    "    recommended_background = x['recommended_background']\n",
    "    target_group = x['target_group']\n",
    "    required_tools = x['required_tools']\n",
    "    text = course_name + ' ' + teacher_intro + ' ' + x['groups'] + ' ' + x['sub_groups'] + ' ' + x['topics'] + ' ' + will_learn + ' ' + recommended_background + ' ' + target_group\n",
    "    return text\n",
    "\n",
    "fillna['combination'] = fillna.apply(create_combination, axis=1)\n",
    "fillna['combination'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import datetime\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words= None)\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(fillna['combination'])\n",
    "\n",
    "#print(tfidf.vocabulary_)\n",
    "tfidf_matrix_nd = tfidf_matrix.toarray()\n",
    "np.save('tfidf_embed/item_embed_.npy', tfidf_matrix_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('少女人妻華麗變身', 9981),\n",
       " ('七大妝容七彩的夢幻樂園', 2036),\n",
       " ('在美妝kol圈裡屬個人風格強烈的alice', 7722),\n",
       " ('在清新與叛逆風格間遊刃有餘', 7693),\n",
       " ('其幽默的美妝影片手法引起許多粉絲的共鳴', 5165)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tfidf.get_feature_names_out()))\n",
    "list(tfidf.vocabulary_.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(728, 23722)\n",
      "(728, 23722)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "item_embed_FM = np.load('tfidf_embed/item_embed_.npy')\n",
    "item_embed_FM = item_embed_FM[:728]\n",
    "print(tfidf_matrix.shape)\n",
    "print(item_embed_FM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(728, 47444)\n"
     ]
    }
   ],
   "source": [
    "concatenate_item_embed_nd = np.concatenate([tfidf_matrix_nd, item_embed_FM/50], axis = 1)\n",
    "print(concatenate_item_embed_nd.shape)\n",
    "concatenate_item_embed = csr_matrix(concatenate_item_embed_nd)\n",
    "# print(concatenate_item_embed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(728, 47444)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(728, 728)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the cosine similarity matrix\n",
    "print(concatenate_item_embed_nd.shape)\n",
    "cosine_sim2 = linear_kernel(concatenate_item_embed, concatenate_item_embed)\n",
    "#Output the shape of tfidf_matrix\n",
    "cosine_sim2.shape\n",
    "# count = CountVectorizer(stop_words='english')\n",
    "# count_matrix = count.fit_transform(fillna['combination'])\n",
    "\n",
    "# cosine_sim2 = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tfidf_save = {\"TfidfVectorizer\": tfidf, \"Tfidf_matrix\": tfidf_matrix, \"lightFM_embeding_matrix\": item_embed_FM, \"concatenate_matrix\": concatenate_item_embed}\n",
    "with open('subgroup_content_embed/all.pickle', 'wb') as f:\n",
    "    pickle.dump(tfidf_save, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根據課程相似度 Predict Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('61888e868f154b000781b45a', [1, 2]),\n",
       " ('54d5a117065a7e0e00725ac0', [3, 4]),\n",
       " ('54d5d9952246e60a009ec571', [3, 5]),\n",
       " ('54d7148a2246e60a009ec588', [3, 6, 5]),\n",
       " ('5513e92b38239d10005778e1', [7, 8])]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgroups_df = pd.read_csv('./data/subgroups.csv')\n",
    "subgroup_num = len(subgroups_df)\n",
    "\n",
    "subgroups2idx = {}\n",
    "for (id, name) in zip(subgroups_df[\"subgroup_id\"], subgroups_df[\"subgroup_name\"]):\n",
    "    subgroups2idx.update({name: id})\n",
    "idx2subgroups = {v : k for k, v in subgroups2idx.items()}\n",
    "\n",
    "course2subgroups = {}\n",
    "for (course_id, sub_groups) in zip(course_df[\"course_id\"], course_df[\"sub_groups\"]):\n",
    "    if pd.isnull(sub_groups):\n",
    "        course2subgroups.update({course_id: [0]})\n",
    "    else:\n",
    "        course2subgroups.update({course_id: [ subgroups2idx[sub_group] for sub_group in sub_groups.split(',')]})\n",
    "\n",
    "list(course2subgroups.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['為申請學校或工作寫好英文自傳']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['職場溝通',\n",
       " '英文',\n",
       " '求職',\n",
       " '更多生活品味',\n",
       " '親子教育',\n",
       " '個人品牌經營',\n",
       " '更多職場技能',\n",
       " '網站架設',\n",
       " '平面設計',\n",
       " '電腦繪圖']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recommendations_new(haved_courses_list, cosine_sim, top = 50):\n",
    "    cosine_sim_sum = [ [i, 0] for i in range(len(course2id_mapping))]\n",
    "    haved_courses_index_list = [ course2id_mapping[course_id] for course_id in haved_courses_list]\n",
    "    for idx in haved_courses_index_list:\n",
    "        # Get the pairwsie similarity scores of all courses with that course\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        for i in range(len(sim_scores)):\n",
    "            cosine_sim_sum[i][1] += sim_scores[i][1]\n",
    "\n",
    "    # Sort the similarity scores\n",
    "    sim_scores = sorted(cosine_sim_sum, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    recommend_subgroups = []\n",
    "    # Get the scores of the top most course not buy\n",
    "    for i in range(len(sim_scores)):\n",
    "        if len(recommend_subgroups) < top:\n",
    "            if sim_scores[i][0] not in haved_courses_index_list:\n",
    "                course_id = course_df['course_id'][sim_scores[i][0]]\n",
    "                for subgroup in course2subgroups[course_id]:\n",
    "                    if subgroup not in recommend_subgroups:\n",
    "                        recommend_subgroups.append(subgroup)\n",
    "\n",
    "    return recommend_subgroups\n",
    "\n",
    "test = ['5513e92b38239d10005778e1']\n",
    "print(course_df['course_name'].iloc[[course2id_mapping[course] for course in test]].tolist())  \n",
    "test_predict = get_recommendations_new(test, cosine_sim2, 10)\n",
    "[ idx2subgroups[subgroup_id] for subgroup_id in test_predict ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7205\n",
      "59737\n"
     ]
    }
   ],
   "source": [
    "seen_predict_df = pd.read_csv('./data/test_seen_group.csv')\n",
    "predict_user = seen_predict_df[\"user_id\"].to_list()\n",
    "print(len(predict_user))\n",
    "\n",
    "\n",
    "seen_user_haved_purchased_course = {}\n",
    "for seen_user_id, course_ids in zip(train_df[\"user_id\"], train_df[\"course_id\"]):\n",
    "    course_id_list = course_ids.split(' ')\n",
    "    seen_user_haved_purchased_course[seen_user_id] = seen_user_haved_purchased_course.setdefault(seen_user_id, []) + course_id_list\n",
    "for seen_user_id, course_ids in zip(val_seen_df[\"user_id\"], val_seen_df[\"course_id\"]):\n",
    "    course_id_list = course_ids.split(' ')\n",
    "    seen_user_haved_purchased_course[seen_user_id] = seen_user_haved_purchased_course.setdefault(seen_user_id, []) + course_id_list\n",
    "print(len(seen_user_haved_purchased_course))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "predict_users = seen_predict_df[\"user_id\"].to_list()\n",
    "with open(\"subgroup_predict.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"user_id\", \"subgroup\"])\n",
    "    for user_id in predict_users:\n",
    "        recommend_subgroups_str = [ str(x) for x in get_recommendations_new(seen_user_haved_purchased_course[user_id], cosine_sim2, top = 50)]\n",
    "        recommend = \" \".join(recommend_subgroups_str)\n",
    "        writer.writerow([user_id, recommend])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_seen_group_df[\"subgroup\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('56dae2b74e3ef90900b7bd0e', [37, 71]),\n",
       " ('60e66f29be3e3b0006c4db75', [1, 14, 15]),\n",
       " ('5c919efb728ddf00208b9b2b', [1, 3, 5, 25, 29, 50, 51, 52, 66, 67, 72, 73]),\n",
       " ('5ac115507997a2001e7c3617', [33, 34, 38, 39]),\n",
       " ('5f53b84440c5be3bb873a9d3', [30])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_haved_purchased_course = {}\n",
    "for seen_user_id, course_ids in zip(train_df[\"user_id\"], train_df[\"course_id\"]):\n",
    "    course_id_list = course_ids.split(' ')\n",
    "    train_user_haved_purchased_course[seen_user_id] = train_user_haved_purchased_course.setdefault(seen_user_id, []) + course_id_list\n",
    "\n",
    "val_answer_subgroups = {}\n",
    "val_seen_group_df_fillna = val_seen_group_df.fillna(\"\")\n",
    "for seen_user_id, subgroup_ids in zip(val_seen_group_df_fillna[\"user_id\"], val_seen_group_df_fillna[\"subgroup\"]):\n",
    "    if len(subgroup_ids) > 0:\n",
    "        course_id_list = [ int(x) for x in subgroup_ids.split(' ')]\n",
    "        val_answer_subgroups[seen_user_id] = val_answer_subgroups.setdefault(seen_user_id, []) + course_id_list\n",
    "list(val_answer_subgroups.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2642995820078796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2642995820078796"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ml_metrics\n",
    "\n",
    "answers = []\n",
    "predictions = []\n",
    "map50s = []\n",
    "for user_id in val_seen_group_df[\"user_id\"]:\n",
    "    prediction = get_recommendations_new(train_user_haved_purchased_course[user_id], cosine_sim2, top = 50)\n",
    "\n",
    "    prediction_idxs = prediction\n",
    "    if user_id in val_answer_subgroups.keys():\n",
    "        answer_idxs = val_answer_subgroups[user_id]\n",
    "    else:\n",
    "        answer_idxs = []\n",
    "\n",
    "    # print(user_id)\n",
    "    # print([course2subgroups[x] for x in train_user_haved_purchased_course[user_id]])\n",
    "    # print(prediction) \n",
    "    # print(answer_idxs)\n",
    "    # print(\"\")\n",
    "\n",
    "    predictions.append(prediction_idxs)\n",
    "    answers.append(answer_idxs)\n",
    "    map50s.append(ml_metrics.mapk(predicted= [prediction_idxs], actual= [answer_idxs], k = 50))\n",
    "    \n",
    "print(np.mean(map50s))\n",
    "#answers.append(answers)        \n",
    "\n",
    "map50 = ml_metrics.mapk(predicted= predictions, actual= answers, k = 50)\n",
    "map50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2707003182647394"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2707003182647394"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use similar user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59737\n",
      "7748\n",
      "11622\n",
      "71359\n",
      "71359\n"
     ]
    }
   ],
   "source": [
    "user_haved_purchased_course = {}\n",
    "\n",
    "train_user_haved_purchased_course = {}\n",
    "for seen_user_id, course_ids in zip(train_df[\"user_id\"], train_df[\"course_id\"]):\n",
    "    course_id_list = course_ids.split(' ')\n",
    "    train_user_haved_purchased_course[seen_user_id] = train_user_haved_purchased_course.setdefault(seen_user_id, []) + course_id_list\n",
    "    user_haved_purchased_course[seen_user_id] = user_haved_purchased_course.setdefault(seen_user_id, []) + course_id_list\n",
    "\n",
    "val_seen_user_haved_purchased_course = {}\n",
    "for seen_user_id, course_ids in zip(val_seen_df[\"user_id\"], val_seen_df[\"course_id\"]):\n",
    "    course_id_list = course_ids.split(' ')\n",
    "    val_seen_user_haved_purchased_course[seen_user_id] = val_seen_user_haved_purchased_course.setdefault(seen_user_id, []) + course_id_list\n",
    "    user_haved_purchased_course[seen_user_id] = user_haved_purchased_course.setdefault(seen_user_id, []) + course_id_list\n",
    "    \n",
    "val_unseen_user_haved_purchased_course = {}\n",
    "for unseen_user_id, course_ids in zip(val_unseen_df[\"user_id\"], val_unseen_df[\"course_id\"]):\n",
    "    course_id_list = course_ids.split(' ')\n",
    "    val_unseen_user_haved_purchased_course[unseen_user_id] = val_unseen_user_haved_purchased_course.setdefault(unseen_user_id, []) + course_id_list\n",
    "    user_haved_purchased_course[unseen_user_id] = user_haved_purchased_course.setdefault(unseen_user_id, []) + course_id_list\n",
    "\n",
    "haved_purchased_users_list = []\n",
    "for user_id in train_user_haved_purchased_course.keys():\n",
    "    if len(train_user_haved_purchased_course[user_id]) >0:\n",
    "        haved_purchased_users_list.append(user_id)\n",
    "for user_id in val_seen_user_haved_purchased_course.keys():\n",
    "    if len(val_seen_user_haved_purchased_course[user_id]) >0:\n",
    "        haved_purchased_users_list.append(user_id)\n",
    "for user_id in val_unseen_user_haved_purchased_course.keys():\n",
    "    if len(val_unseen_user_haved_purchased_course[user_id]) >0:\n",
    "        haved_purchased_users_list.append(user_id)\n",
    "haved_purchased_users_list = list(set(haved_purchased_users_list))    \n",
    "\n",
    "print(len(train_user_haved_purchased_course))\n",
    "print(len(val_seen_user_haved_purchased_course))\n",
    "print(len(val_unseen_user_haved_purchased_course))\n",
    "print(len(haved_purchased_users_list))\n",
    "print(len(user_haved_purchased_course))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('subgroup_content_embed/unseen_user_similar_add_course.pickle', 'rb+')\n",
    "info = pickle.load(f)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'subgroup_content_embed/unseen_user_similar_course.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39msubgroup_content_embed/unseen_user_similar_course.pickle\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     test_predict_similiar_users \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(test_predict_similiar_users[\u001b[39m\"\u001b[39m\u001b[39msimilar_users\u001b[39m\u001b[39m\"\u001b[39m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/adlhw3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'subgroup_content_embed/unseen_user_similar_course.pickle'"
     ]
    }
   ],
   "source": [
    "with open('similar_user/unseen_user_similar_course.pickle', 'rb') as f:\n",
    "    test_predict_similiar_users = pickle.load(f)\n",
    "    \n",
    "print(len(test_predict_similiar_users[\"similar_users\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommend_subgroup_by_users(user_id, similar_users_list, top = 50):\n",
    "    # print(user_index)\n",
    "    recommend_subgroups = []\n",
    "    recommend_course_ids = []\n",
    "    similar_users_list #= test_predict_similiar_users[user_id]\n",
    "    for similar_user in similar_users_list:\n",
    "        if similar_user in val_seen_user_haved_purchased_course.keys():\n",
    "            for course_id in val_seen_user_haved_purchased_course[similar_user]:\n",
    "                if len(recommend_subgroups)>top:\n",
    "                    break\n",
    "                if course_id not in recommend_course_ids:\n",
    "                    if user_id in val_unseen_user_haved_purchased_course.keys():\n",
    "                        if course_id not in val_unseen_user_haved_purchased_course[user_id]:\n",
    "                            recommend_course_ids.append(course_id)\n",
    "                            for subgroup in course2subgroups[course_id]:\n",
    "                                if subgroup not in recommend_subgroups:\n",
    "                                    recommend_subgroups.append(subgroup)\n",
    "                    else:\n",
    "                        recommend_course_ids.append(course_id)\n",
    "                        for subgroup in course2subgroups[course_id]:\n",
    "                            if subgroup not in recommend_subgroups:\n",
    "                                recommend_subgroups.append(subgroup)\n",
    "        \n",
    "        if similar_user in train_user_haved_purchased_course.keys():           \n",
    "            for course_id in train_user_haved_purchased_course[similar_user]:\n",
    "                if len(recommend_subgroups)>top:\n",
    "                    break\n",
    "                if course_id not in recommend_course_ids:\n",
    "                    if user_id in val_unseen_user_haved_purchased_course.keys():\n",
    "                        if course_id not in val_unseen_user_haved_purchased_course[user_id]:\n",
    "                            recommend_course_ids.append(course_id)\n",
    "                            for subgroup in course2subgroups[course_id]:\n",
    "                                if subgroup not in recommend_subgroups:\n",
    "                                    recommend_subgroups.append(subgroup)\n",
    "                    else:\n",
    "                        recommend_course_ids.append(course_id)\n",
    "                        for subgroup in course2subgroups[course_id]:\n",
    "                            if subgroup not in recommend_subgroups:\n",
    "                                recommend_subgroups.append(subgroup)\n",
    "                        \n",
    "        if similar_user in val_unseen_user_haved_purchased_course.keys():           \n",
    "            for course_id in val_unseen_user_haved_purchased_course[similar_user]:\n",
    "                if len(recommend_subgroups)>top:\n",
    "                    break\n",
    "                if course_id not in recommend_course_ids:\n",
    "                    if user_id in val_unseen_user_haved_purchased_course.keys():\n",
    "                        if course_id not in val_unseen_user_haved_purchased_course[user_id]:\n",
    "                            recommend_course_ids.append(course_id)\n",
    "                            for subgroup in course2subgroups[course_id]:\n",
    "                                if subgroup not in recommend_subgroups:\n",
    "                                    recommend_subgroups.append(subgroup)\n",
    "                    else:\n",
    "                        recommend_course_ids.append(course_id)\n",
    "                        for subgroup in course2subgroups[course_id]:\n",
    "                            if subgroup not in recommend_subgroups:\n",
    "                                recommend_subgroups.append(subgroup)\n",
    "                \n",
    "    # Return the top 10 most similar users\n",
    "    return recommend_subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                                       5f1dc5a3afdc0537b5de8979\n",
      "gender                                                          female\n",
      "occupation_titles                                              製造業,服務業\n",
      "interests            投資理財_理財,程式_量化分析,投資理財_投資觀念,職場技能_效率提升,投資理財_金融商品,...\n",
      "recreation_names                                             旅行旅遊,金融理財\n",
      "Name: 39502, dtype: object\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_predict_similiar_users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m test \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m5f1dc5a3afdc0537b5de8979\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(users_df\u001b[39m.\u001b[39miloc[user2id_mapping[test]])  \n\u001b[0;32m----> 3\u001b[0m test_predict \u001b[39m=\u001b[39m get_recommend_subgroup_by_users(test, test_predict_similiar_users[\u001b[39m\"\u001b[39m\u001b[39msimilar_users\u001b[39m\u001b[39m\"\u001b[39m][test], \u001b[39m50\u001b[39m)\n\u001b[1;32m      4\u001b[0m [ idx2subgroups[subgroup_id] \u001b[39mfor\u001b[39;00m subgroup_id \u001b[39min\u001b[39;00m test_predict ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_predict_similiar_users' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "test = '5f1dc5a3afdc0537b5de8979'\n",
    "print(users_df.iloc[user2id_mapping[test]])  \n",
    "test_predict = get_recommend_subgroup_by_users(test, test_predict_similiar_users[\"similar_users\"][test], 50)\n",
    "[ idx2subgroups[subgroup_id] for subgroup_id in test_predict ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Course by similar user and course embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "### seen unseen\n",
    "\n",
    "#with open(r'similar_users\\seen_user_similar_add_course.pickle', 'rb') as f:\n",
    "with open(r'similar_user\\unseen_user_similar_course.pickle', 'rb') as f:\n",
    "    test_predict_similiar_users = pickle.load(f)\n",
    "    \n",
    "print(len(test_predict_similiar_users[\"similar_users\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_course_score_by_course_embedding(cosine_sim_sum, haved_courses_list, weight, cosine_sim):\n",
    "    haved_courses_index_list = [ course2id_mapping[course_id] for course_id in haved_courses_list]\n",
    "    for idx in haved_courses_index_list:\n",
    "        # Get the pairwsie similarity scores of all courses with that course\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        for i in range(len(sim_scores)):\n",
    "            cosine_sim_sum[i][1] += weight*sim_scores[i][1]\n",
    "\n",
    "    return cosine_sim_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_course_by_course_embedding_and_similar_users(user_id, similar_users_list, similar_user_weights_list, cosine_sim, top = 50):\n",
    "    # print(user_index)\n",
    "    cosine_sim_sum = [ [i, 0] for i in range(len(course2id_mapping))]\n",
    "\n",
    "    if user_id in user_haved_purchased_course.keys():\n",
    "        cosine_sim_sum = get_course_score_by_course_embedding(cosine_sim_sum, user_haved_purchased_course[user_id], 1, cosine_sim)\n",
    "    for similar_user, similar_user_weight in zip(similar_users_list, similar_user_weights_list):\n",
    "        cosine_sim_sum = get_course_score_by_course_embedding(cosine_sim_sum, user_haved_purchased_course[similar_user], similar_user_weight, cosine_sim)\n",
    "        #print(similar_user_weight)\n",
    "\n",
    "    sim_scores = sorted(cosine_sim_sum, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    recommend_subgroups = []\n",
    "    # Get the scores of the 50 most course not buy\n",
    "    for i in range(len(sim_scores)):\n",
    "        if len(recommend_subgroups) < top:\n",
    "            if user_id in user_haved_purchased_course.keys():\n",
    "                if id2course_mapping[sim_scores[i][0]]not in user_haved_purchased_course[user_id]:\n",
    "                    course_id = course_df['course_id'][sim_scores[i][0]]\n",
    "                    for subgroup in course2subgroups[course_id]:\n",
    "                        if subgroup not in recommend_subgroups:\n",
    "                            recommend_subgroups.append(subgroup)\n",
    "            else:\n",
    "                course_id = course_df['course_id'][sim_scores[i][0]]\n",
    "                for subgroup in course2subgroups[course_id]:\n",
    "                    if subgroup not in recommend_subgroups:\n",
    "                        recommend_subgroups.append(subgroup)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Return the top \n",
    "    return recommend_subgroups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11097/11097 [05:29<00:00, 33.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#test_predict_users = test_seen_df[\"user_id\"].to_list()\n",
    "test_predict_users = test_unseen_df[\"user_id\"].to_list()\n",
    "print(len(test_predict_users))\n",
    "count = []\n",
    "with open(\"predictions/unseen_subgroup_by_similar_course_embedding_75.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"user_id\", \"subgroup\"])\n",
    "    for user_id in tqdm(test_predict_users):\n",
    "        #predictions = get_recommend_subgroup_by_users(user_id, test_predict_similiar_users[\"similar_users\"][user_id], top = 50)\n",
    "        predictions = get_recommendations_course_by_course_embedding_and_similar_users(user_id, \n",
    "                    test_predict_similiar_users[\"similar_users\"][user_id][:75], test_predict_similiar_users[\"similar_user_weights\"][user_id][:75], cosine_sim2, 50)\n",
    "        recommend = \" \".join([ str(x) for x in predictions])\n",
    "        writer.writerow([user_id, recommend])\n",
    "        count.append(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47.20446967648914"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero = 0\n",
    "not_zero = [] \n",
    "for x in count:\n",
    "    if x < 30:\n",
    "        zero += 1\n",
    "    else:\n",
    "        not_zero.append(x)\n",
    "print(zero)\n",
    "np.mean(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48, 51, 51, 48, 51, 49, 44, 51, 51, 51]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlhw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dedd2b11c6d65023ba78f004c00adcb97ea7737d51ff1d03c402b08b92e7cef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
