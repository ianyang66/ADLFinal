{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_chapter_items_df = pd.read_csv('./data/course_chapter_items.csv')\n",
    "course_df = pd.read_csv('./data/courses.csv')\n",
    "users_df = pd.read_csv('./data/users.csv')\n",
    "subgroups_df = pd.read_csv('./data/subgroups.csv')\n",
    "\n",
    "train_group_df = pd.read_csv('./data/train_group.csv')\n",
    "test_seen_group_df = pd.read_csv('./data/test_seen_group.csv')\n",
    "val_seen_group_df = pd.read_csv('./data/val_seen_group.csv')\n",
    "test_unseen_group_df = pd.read_csv('./data/test_unseen_group.csv')\n",
    "val_unseen_group_df = pd.read_csv('./data/val_unseen_group.csv')\n",
    "\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_seen_df = pd.read_csv('./data/test_seen.csv')\n",
    "val_seen_df = pd.read_csv('./data/val_seen.csv')\n",
    "test_unseen_df = pd.read_csv('./data/test_unseen.csv')\n",
    "val_unseen_df = pd.read_csv('./data/val_unseen.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation_titles</th>\n",
       "      <th>interests</th>\n",
       "      <th>recreation_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54ccaa73a784960a00948687</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>職場技能_創業,藝術_電腦繪圖,設計_介面設計,設計_動態設計,設計_平面設計,投資理財_投...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54dca4456d7d350900e86bae</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>設計_動態設計,設計_平面設計,設計_應用設計,程式_程式入門,程式_程式語言,藝術_角色設...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54e421bac5c9c00900cd8d47</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>設計_平面設計,職場技能_資料彙整,藝術_繪畫與插畫,行銷_數位行銷,職場技能_文書處理,職...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54e961d4c5c9c00900cd8d84</td>\n",
       "      <td>other</td>\n",
       "      <td>金融業</td>\n",
       "      <td>投資理財_理財,攝影_影像創作,投資理財_投資觀念,藝術_更多藝術,音樂_樂器,投資理財_金...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54e9b744c5c9c00900cd8d8a</td>\n",
       "      <td>other</td>\n",
       "      <td>資訊科技,法律、社會及文化專業,非營利組織</td>\n",
       "      <td>程式_網頁前端,投資理財_理財,投資理財_投資觀念,程式_程式語言,設計_設計理論,投資理財...</td>\n",
       "      <td>政治經濟,社會服務,舞台劇,電影</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user_id  gender      occupation_titles  \\\n",
       "0  54ccaa73a784960a00948687  female                    NaN   \n",
       "1  54dca4456d7d350900e86bae    male                    NaN   \n",
       "2  54e421bac5c9c00900cd8d47  female                    NaN   \n",
       "3  54e961d4c5c9c00900cd8d84   other                    金融業   \n",
       "4  54e9b744c5c9c00900cd8d8a   other  資訊科技,法律、社會及文化專業,非營利組織   \n",
       "\n",
       "                                           interests  recreation_names  \n",
       "0  職場技能_創業,藝術_電腦繪圖,設計_介面設計,設計_動態設計,設計_平面設計,投資理財_投...               NaN  \n",
       "1  設計_動態設計,設計_平面設計,設計_應用設計,程式_程式入門,程式_程式語言,藝術_角色設...               NaN  \n",
       "2  設計_平面設計,職場技能_資料彙整,藝術_繪畫與插畫,行銷_數位行銷,職場技能_文書處理,職...               NaN  \n",
       "3  投資理財_理財,攝影_影像創作,投資理財_投資觀念,藝術_更多藝術,音樂_樂器,投資理財_金...               NaN  \n",
       "4  程式_網頁前端,投資理財_理財,投資理財_投資觀念,程式_程式語言,設計_設計理論,投資理財...  政治經濟,社會服務,舞台劇,電影  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130566"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2user_mapping = users_df[\"user_id\"].to_dict()\n",
    "user2id_mapping = {v : k for k, v in id2user_mapping.items()}\n",
    "len(id2user_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation_titles</th>\n",
       "      <th>interests</th>\n",
       "      <th>recreation_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td></td>\n",
       "      <td>職場技能_創業,藝術_電腦繪圖,設計_介面設計,設計_動態設計,設計_平面設計,投資理財_投...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td></td>\n",
       "      <td>設計_動態設計,設計_平面設計,設計_應用設計,程式_程式入門,程式_程式語言,藝術_角色設...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td></td>\n",
       "      <td>設計_平面設計,職場技能_資料彙整,藝術_繪畫與插畫,行銷_數位行銷,職場技能_文書處理,職...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>金融業</td>\n",
       "      <td>投資理財_理財,攝影_影像創作,投資理財_投資觀念,藝術_更多藝術,音樂_樂器,投資理財_金...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>資訊科技,法律、社會及文化專業,非營利組織</td>\n",
       "      <td>程式_網頁前端,投資理財_理財,投資理財_投資觀念,程式_程式語言,設計_設計理論,投資理財...</td>\n",
       "      <td>政治經濟,社會服務,舞台劇,電影</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender      occupation_titles  \\\n",
       "0  female                          \n",
       "1    male                          \n",
       "2  female                          \n",
       "3                            金融業   \n",
       "4          資訊科技,法律、社會及文化專業,非營利組織   \n",
       "\n",
       "                                           interests  recreation_names  \n",
       "0  職場技能_創業,藝術_電腦繪圖,設計_介面設計,設計_動態設計,設計_平面設計,投資理財_投...                    \n",
       "1  設計_動態設計,設計_平面設計,設計_應用設計,程式_程式入門,程式_程式語言,藝術_角色設...                    \n",
       "2  設計_平面設計,職場技能_資料彙整,藝術_繪畫與插畫,行銷_數位行銷,職場技能_文書處理,職...                    \n",
       "3  投資理財_理財,攝影_影像創作,投資理財_投資觀念,藝術_更多藝術,音樂_樂器,投資理財_金...                    \n",
       "4  程式_網頁前端,投資理財_理財,投資理財_投資觀念,程式_程式語言,設計_設計理論,投資理財...  政治經濟,社會服務,舞台劇,電影  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(x):\n",
    "    x = x.replace(\"其他\", \"\")\n",
    "    x = x.replace(\"other\", \"\")\n",
    "    return x\n",
    "\n",
    "fillna = users_df.fillna('')\n",
    "features = ['gender', 'occupation_titles', 'interests', 'recreation_names']\n",
    "fillna = fillna[features]\n",
    "for feature in features:\n",
    "    fillna[feature] = fillna[feature].apply(clean_data)\n",
    "    \n",
    "fillna.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combination(x):\n",
    "    return x['gender']+ ' ' + x['occupation_titles'] + ' ' + x['interests'] + ' ' + x['recreation_names']\n",
    "\n",
    "fillna['combination'] = fillna.apply(create_combination, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    female  職場技能_創業,藝術_電腦繪圖,設計_介面設計,設計_動態設計,設計_平面設...\n",
       "1    male  設計_動態設計,設計_平面設計,設計_應用設計,程式_程式入門,程式_程式語言,...\n",
       "2    female  設計_平面設計,職場技能_資料彙整,藝術_繪畫與插畫,行銷_數位行銷,職場技...\n",
       "3     金融業 投資理財_理財,攝影_影像創作,投資理財_投資觀念,藝術_更多藝術,音樂_樂器,投...\n",
       "4     資訊科技,法律、社會及文化專業,非營利組織 程式_網頁前端,投資理財_理財,投資理財_投資...\n",
       "Name: combination, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fillna['combination'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not a built-in stop list: enlish",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m#Construct the required TF-IDF matrix by fitting and transforming the data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m tfidf \u001b[39m=\u001b[39m TfidfVectorizer(stop_words\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39menlish\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m tfidf_matrix \u001b[39m=\u001b[39m tfidf\u001b[39m.\u001b[39;49mfit_transform(fillna[\u001b[39m'\u001b[39;49m\u001b[39mcombination\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      9\u001b[0m \u001b[39m# Compute the cosine similarity matrix\u001b[39;00m\n\u001b[1;32m     10\u001b[0m cosine_sim2 \u001b[39m=\u001b[39m linear_kernel(tfidf_matrix, tfidf_matrix)\n",
      "File \u001b[0;32m~/miniconda3/envs/adlhw3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:2079\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2072\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[1;32m   2073\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf \u001b[39m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2074\u001b[0m     norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm,\n\u001b[1;32m   2075\u001b[0m     use_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf,\n\u001b[1;32m   2076\u001b[0m     smooth_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth_idf,\n\u001b[1;32m   2077\u001b[0m     sublinear_tf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msublinear_tf,\n\u001b[1;32m   2078\u001b[0m )\n\u001b[0;32m-> 2079\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[1;32m   2080\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[1;32m   2081\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2082\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/adlhw3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1338\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1330\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1331\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1332\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1333\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1334\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1335\u001b[0m             )\n\u001b[1;32m   1336\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1338\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[1;32m   1340\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[1;32m   1341\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/adlhw3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1201\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     vocabulary \u001b[39m=\u001b[39m defaultdict()\n\u001b[1;32m   1199\u001b[0m     vocabulary\u001b[39m.\u001b[39mdefault_factory \u001b[39m=\u001b[39m vocabulary\u001b[39m.\u001b[39m\u001b[39m__len__\u001b[39m\n\u001b[0;32m-> 1201\u001b[0m analyze \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_analyzer()\n\u001b[1;32m   1202\u001b[0m j_indices \u001b[39m=\u001b[39m []\n\u001b[1;32m   1203\u001b[0m indptr \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/adlhw3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:454\u001b[0m, in \u001b[0;36m_VectorizerMixin.build_analyzer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[39mreturn\u001b[39;00m partial(\n\u001b[1;32m    447\u001b[0m         _analyze,\n\u001b[1;32m    448\u001b[0m         ngrams\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_char_wb_ngrams,\n\u001b[1;32m    449\u001b[0m         preprocessor\u001b[39m=\u001b[39mpreprocess,\n\u001b[1;32m    450\u001b[0m         decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode,\n\u001b[1;32m    451\u001b[0m     )\n\u001b[1;32m    453\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalyzer \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mword\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 454\u001b[0m     stop_words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_stop_words()\n\u001b[1;32m    455\u001b[0m     tokenize \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_tokenizer()\n\u001b[1;32m    456\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_stop_words_consistency(stop_words, preprocess, tokenize)\n",
      "File \u001b[0;32m~/miniconda3/envs/adlhw3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:376\u001b[0m, in \u001b[0;36m_VectorizerMixin.get_stop_words\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_stop_words\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    369\u001b[0m     \u001b[39m\"\"\"Build or fetch the effective stop words list.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[1;32m    371\u001b[0m \u001b[39m    Returns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[39m            A list of stop words.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_stop_list(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstop_words)\n",
      "File \u001b[0;32m~/miniconda3/envs/adlhw3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:196\u001b[0m, in \u001b[0;36m_check_stop_list\u001b[0;34m(stop)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[39mreturn\u001b[39;00m ENGLISH_STOP_WORDS\n\u001b[1;32m    195\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(stop, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnot a built-in stop list: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m stop)\n\u001b[1;32m    197\u001b[0m \u001b[39melif\u001b[39;00m stop \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not a built-in stop list: enlish"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(fillna['combination'])\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim2 = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# count = CountVectorizer()\n",
    "# count_matrix = count.fit_transform(fillna['combination'])\n",
    "# cosine_sim2 = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tfidf_save = {\"TfidfVectorizer\": tfidf, \"Tfidf_matrix\": tfidf_matrix}\n",
    "with open('user_embedding.pickle', 'wb') as f:\n",
    "    pickle.dump(tfidf_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 149)\n",
      "{'female': 0, '職場技能_創業': 84, '藝術_電腦繪圖': 106, '設計_介面設計': 113, '設計_動態設計': 114, '設計_平面設計': 115, '投資理財_投資觀念': 24, '行銷_數位行銷': 107, '藝術_角色設計': 105, '藝術_繪畫與插畫': 102, '職場技能_個人品牌經營': 83, 'male': 1, '設計_應用設計': 116, '程式_程式入門': 69, '程式_程式語言': 72, '程式_網頁前端': 74, '音樂_音樂創作': 147, '職場技能_資料彙整': 92, '職場技能_文書處理': 86, '職場技能_職場溝通': 91, '金融業': 135, '投資理財_理財': 27, '攝影_影像創作': 34, '藝術_更多藝術': 100, '音樂_樂器': 146, '投資理財_金融商品': 29, '資訊科技': 128, '法律': 47, '社會及文化專業': 62, '非營利組織': 142, '設計_設計理論': 119, '政治經濟': 39, '社會服務': 63, '舞台劇': 95, '電影': 138, '行銷_文案': 109, '攝影_商業攝影': 33, '插畫': 30, '桌遊': 44, '棋類遊戲': 45, '素描': 81, '電玩': 139, '藝文設計': 97, '自由業': 94, '音樂_人聲': 144, '程式_遊戲開發': 79, '藝術_字體設計': 98, '狗派': 49, '運動健身': 132, '電腦繪圖': 140, '出版業': 7, '職場技能_求職': 88, '職場技能_效率提升': 85, '設計_網頁設計': 118, '語言_更多語言': 121, '生活品味_親子教育': 58, '語言_英文': 124, '手作_手工印刷': 16, '手作_刺繡': 14, '手作_更多手作': 18, '手作_手工書': 17, '語言_韓文': 126, '手作_手作小物': 15, '寫作': 11, '手作': 13, '手寫字': 22, '手遊': 23, '水彩': 46, '速寫': 131, '閱讀': 137, '程式_程式思維': 70, '程式_程式理財': 71, '攝影_後製剪輯': 36, '音樂_音樂理論': 148, '藝術_手寫字': 99, '廣告傳播': 12, '語言_歐洲語言': 122, '攝影_影視創作': 35, '程式_網站架設': 73, '生活品味_烹飪料理與甜點': 57, '占卜': 9, '醫療': 134, '程式_量化分析': 80, '生活品味_更多生活品味': 56, '生活品味_運動': 60, '人文_文學': 3, '藝術_色彩學': 103, '語言_西班牙文': 125, '生活品味_寵物': 52, '語言_日文': 120, '藝術_素描': 101, '職場技能_產品設計': 90, '行銷_社群行銷': 111, '電視劇': 141, '旅行旅遊': 41, '書法': 42, '美容妝髮': 82, '攝影_動態攝影': 32, '設計_更多設計': 117, '瑜珈': 50, '貓派': 127, '程式_資料科學': 76, '程式_網頁後端': 75, '程式_手機程式開發': 67, '營建工程': 48, '服務業': 43, '舞蹈': 96, '運動賽事': 133, '程式_資訊安全': 77, '手作_篆刻': 21, '生活品味_護膚保養與化妝': 59, '生活品味_心靈成長與教育': 54, '生活品味_壓力舒緩': 51, '人文_社會科學': 5, '生活品味_靈性發展': 61, '插花': 31, '公務人員': 6, '職場技能_更多職場技能': 87, '科技業': 64, '教學專業': 40, '程式_軟體程式開發與維護': 78, '投資理財_比特幣': 26, '製造業': 112, '金融理財': 136, '程式_區塊鏈': 66, '人文_更多人文': 4, '生活品味_數學': 55, '區塊鏈': 8, '程式_更多程式': 68, '行銷_更多行銷': 110, '手作_氣球': 20, '攝影_攝影理論': 37, '投資理財_更多投資理財': 25, '攝影_更多攝影': 38, '音樂_dj': 143, '退休': 130, '音樂_更多音樂': 145, '家管': 10, '農林漁牧': 129, '投資理財_量化交易': 28, '行銷_數據分析': 108, '程式_ai': 65, '人工智慧': 2, '職場技能_獨立接案': 89, '手作_模型': 19, '職業軍人': 93, '語言_翻譯': 123, '生活品味_居家': 53, '藝術_表演藝術': 104}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix.shape)\n",
    "print(tfidf.vocabulary_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推薦最相近的users，我拿items改的，input其實只會有一個user而已"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['57332668fad4ef0a006b22dc', '569e36cc4ec4c609007d2537', '57332b4cfad4ef0a006b236d', '59b9f021cd5792070055f6ef', '575c1b65f1399b0900e20d3d']\n",
      "原本user: ['female  職場技能_創業,藝術_電腦繪圖,設計_介面設計,設計_動態設計,設計_平面設計,投資理財_投資觀念,行銷_數位行銷,藝術_角色設計,藝術_繪畫與插畫,職場技能_個人品牌經營 ']\n",
      "推薦:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['female  設計_介面設計,設計_動態設計,設計_網頁設計,藝術_電腦繪圖,藝術_繪畫與插畫,設計_平面設計,藝術_角色設計 ',\n",
       " 'male  設計_介面設計,設計_動態設計,藝術_電腦繪圖,藝術_繪畫與插畫,設計_平面設計,藝術_角色設計 ',\n",
       " 'female  投資理財_理財,設計_介面設計,設計_平面設計,設計_應用設計,藝術_電腦繪圖,設計_動態設計,投資理財_投資觀念,設計_網頁設計,藝術_角色設計,藝術_繪畫與插畫 ',\n",
       " 'female  設計_平面設計,藝術_角色設計,藝術_電腦繪圖,設計_動態設計,行銷_數位行銷,藝術_繪畫與插畫 ',\n",
       " 'male  藝術_電腦繪圖,設計_介面設計,設計_動態設計,設計_網頁設計,藝術_角色設計,藝術_繪畫與插畫 ']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recommend_users(user_list, cosine_sim, top = 10):\n",
    "    cosine_sim_sum = [ [i, 0] for i in range(len(user2id_mapping))]\n",
    "    user_index_list = [ user2id_mapping[user_id] for user_id in user_list]\n",
    "    for idx in user_index_list:\n",
    "        # Get the pairwsie similarity scores of all courses with that course\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        for i in range(len(sim_scores)):\n",
    "            cosine_sim_sum[i][1] += sim_scores[i][1]\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(cosine_sim_sum, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    recommend_indices = []\n",
    "    # Get the scores of the 10 most course not buy\n",
    "    for i in range(len(sim_scores)):\n",
    "        if len(recommend_indices) < top:\n",
    "            if sim_scores[i][0] not in user_index_list:\n",
    "                recommend_indices.append(sim_scores[i][0])\n",
    "\n",
    "    # Return the top 10 most similar users\n",
    "    return recommend_indices\n",
    "    \n",
    "recommend_indices = get_recommend_users(['54ccaa73a784960a00948687'], cosine_sim2, 5)\n",
    "print(users_df['user_id'].iloc[recommend_indices].tolist())\n",
    "print(f\"原本user: {fillna['combination'].iloc[[user2id_mapping['54ccaa73a784960a00948687']]].tolist()}\\n推薦:\")\n",
    "fillna['combination'].iloc[recommend_indices].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlhw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dedd2b11c6d65023ba78f004c00adcb97ea7737d51ff1d03c402b08b92e7cef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
